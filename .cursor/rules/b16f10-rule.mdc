---
description: 
globs: *gds.txt
alwaysApply: false
---

# Your rule content

- Assume all heavy computations will be run on the Digital Research Alliance of Canada's SLURM-managed HPC cluster
- Parallelization and high-speed code is essential
- Code should be written in python or R
- Once code reaches 300-400 lines, refactor into separate scripts like functions.py, search.sh, etc.
- Include logging often
- Always prefer common bioinformatics pipelines and tools over niche ones
- Use a nested folder structure i.e.
main/
│── GSE254073/                           # Each GSE ID has its own folder
│   ├── GSE254073_geo_object.rds         # Full GEO object
│   ├── GSE254073_series_matrix.txt.gz   # Expression matrix
│   ├── samples/                         # Sample-level data
│   │   ├── GSM8756330/                   # Each sample (GSM ID) has a subfolder
│   │   │   ├── GSM8756330.rds             # Sample GEO object
│   │   │   ├── SRA/                        # Raw sequencing data
│   │   │   │   ├── SRR12345678.sra         # Raw SRA file
│   │   │   │   ├── FASTQ/                  # Converted FASTQ files
│   │   │   │   │   ├── SRR12345678_1.fastq.gz
│   │   │   │   │   ├── SRR12345678_2.fastq.gz
│   │   │   ├── alignment/                   # Alignment results
│   │   │   │   ├── SRR12345678.bam
│   │   │   ├── quantification/              # Quantification results
│   │   │   │   ├── SRR12345678_counts.txt
│── scripts/                                # Pipeline scripts
│── logs/                                   # Logs from processing steps
│── results/                                # Final processed data and reports
│── README.md                               # Documentation